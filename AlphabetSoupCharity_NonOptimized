{"cells":[{"cell_type":"markdown","metadata":{"id":"PeZLhDzbQHup"},"source":["## Preprocessing"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":276},"id":"tZBQwlxeQHur","executionInfo":{"status":"ok","timestamp":1645752248219,"user_tz":480,"elapsed":18688,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"8c71d364-2782-48c7-9880-9deaf3308eee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","AlphabetSoupCharity.h5\t\t\tcharity_data.csv  Starter_Code.ipynb\n","AlphabetSoupCharity_Optimization.h5\tmodel.h5\n","AlphabetSoupCharity_Optimization.ipynb\tREADME.md\n"]},{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-a478bc90-70e8-42a5-be3c-4332255914f9\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>EIN</th>\n","      <th>NAME</th>\n","      <th>APPLICATION_TYPE</th>\n","      <th>AFFILIATION</th>\n","      <th>CLASSIFICATION</th>\n","      <th>USE_CASE</th>\n","      <th>ORGANIZATION</th>\n","      <th>STATUS</th>\n","      <th>INCOME_AMT</th>\n","      <th>SPECIAL_CONSIDERATIONS</th>\n","      <th>ASK_AMT</th>\n","      <th>IS_SUCCESSFUL</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>10520599</td>\n","      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n","      <td>T10</td>\n","      <td>Independent</td>\n","      <td>C1000</td>\n","      <td>ProductDev</td>\n","      <td>Association</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>5000</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>10531628</td>\n","      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n","      <td>T3</td>\n","      <td>Independent</td>\n","      <td>C2000</td>\n","      <td>Preservation</td>\n","      <td>Co-operative</td>\n","      <td>1</td>\n","      <td>1-9999</td>\n","      <td>N</td>\n","      <td>108590</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>10547893</td>\n","      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n","      <td>T5</td>\n","      <td>CompanySponsored</td>\n","      <td>C3000</td>\n","      <td>ProductDev</td>\n","      <td>Association</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>N</td>\n","      <td>5000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>10553066</td>\n","      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n","      <td>T3</td>\n","      <td>CompanySponsored</td>\n","      <td>C2000</td>\n","      <td>Preservation</td>\n","      <td>Trust</td>\n","      <td>1</td>\n","      <td>10000-24999</td>\n","      <td>N</td>\n","      <td>6692</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>10556103</td>\n","      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n","      <td>T3</td>\n","      <td>Independent</td>\n","      <td>C1000</td>\n","      <td>Heathcare</td>\n","      <td>Trust</td>\n","      <td>1</td>\n","      <td>100000-499999</td>\n","      <td>N</td>\n","      <td>142590</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a478bc90-70e8-42a5-be3c-4332255914f9')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a478bc90-70e8-42a5-be3c-4332255914f9 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a478bc90-70e8-42a5-be3c-4332255914f9');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["        EIN                                      NAME  ... ASK_AMT IS_SUCCESSFUL\n","0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB  ...    5000             1\n","1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR  ...  108590             1\n","2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS  ...    5000             0\n","3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION  ...    6692             1\n","4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT  ...  142590             1\n","\n","[5 rows x 12 columns]"]},"metadata":{},"execution_count":3}],"source":["# Import our dependencies\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from google.colab import drive, files\n","import pandas as pd\n","import tensorflow as tf\n","\n","#  Import and read the charity_data.csv.\n","import pandas as pd \n","\n","# uploaded = files.upload()\n","\n","drive.mount('/content/drive')\n","\n","!ls \"/content/drive/My Drive/ML_Colab/21-Deep-Learning/Homework/Instructions\"\n","\n","application_df = pd.read_csv('/content/drive/My Drive/ML_Colab/21-Deep-Learning/Homework/Instructions/charity_data.csv')\n","\n","application_df.head()\n"]},{"cell_type":"markdown","source":["# Preprocess the data for ML modeling"],"metadata":{"id":"qRL91VOO3LJW"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"mXVPnZYpQHus","executionInfo":{"status":"ok","timestamp":1645752254756,"user_tz":480,"elapsed":128,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"outputs":[],"source":["# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n","data = application_df.drop(columns = ['EIN','NAME'])"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"UWUI120PQHut","outputId":"fa84c3b4-e7d2-4015-93c6-266225499837","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645752255635,"user_tz":480,"elapsed":155,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["APPLICATION_TYPE            17\n","AFFILIATION                  6\n","CLASSIFICATION              71\n","USE_CASE                     5\n","ORGANIZATION                 4\n","STATUS                       2\n","INCOME_AMT                   9\n","SPECIAL_CONSIDERATIONS       2\n","ASK_AMT                   8747\n","IS_SUCCESSFUL                2\n","dtype: int64"]},"metadata":{},"execution_count":5}],"source":["# Determine the number of unique values in each column.\n","data.nunique()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"zYsbbI1GQHut","outputId":"74bad4ea-2ba2-409d-9458-4b8682f13ed6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645752257029,"user_tz":480,"elapsed":166,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["T3     27037\n","T4      1542\n","T6      1216\n","T5      1173\n","T19     1065\n","T8       737\n","T7       725\n","T10      528\n","T9       156\n","T13       66\n","T12       27\n","T2        16\n","T25        3\n","T14        3\n","T29        2\n","T15        2\n","T17        1\n","Name: APPLICATION_TYPE, dtype: int64"]},"metadata":{},"execution_count":6}],"source":["# Look at APPLICATION_TYPE value counts for binning\n","data['APPLICATION_TYPE'].value_counts()"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ksUssTbmQHut","outputId":"dc565fa5-87c8-4c16-fee2-0746fd820b6a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645752257356,"user_tz":480,"elapsed":166,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["T3       27037\n","T4        1542\n","T6        1216\n","T5        1173\n","T19       1065\n","T8         737\n","T7         725\n","T10        528\n","T9         156\n","T13         66\n","Other       54\n","Name: APPLICATION_TYPE, dtype: int64"]},"metadata":{},"execution_count":7}],"source":["# Choose a cutoff value and create a list of application types to be replaced\n","# use the variable name `application_types_to_replace`\n","\n","application_types_to_replace = ['T25', 'T14', 'T29', 'T15', 'T17', 'T2', 'T12']\n","\n","# Replace in dataframe\n","for app in application_types_to_replace:\n","    data['APPLICATION_TYPE'] = data['APPLICATION_TYPE'].replace(app,\"Other\")\n","\n","# Check to make sure binning was successful\n","data['APPLICATION_TYPE'].value_counts()"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"_HOW5T6PQHut","outputId":"d56d7c3e-68c4-4915-8fe0-88e1b349ec36","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645752258921,"user_tz":480,"elapsed":137,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["C1000    17326\n","C2000     6074\n","C1200     4837\n","C3000     1918\n","C2100     1883\n","         ...  \n","C4120        1\n","C8210        1\n","C2561        1\n","C4500        1\n","C2150        1\n","Name: CLASSIFICATION, Length: 71, dtype: int64"]},"metadata":{},"execution_count":8}],"source":["# Look at CLASSIFICATION value counts for binning\n","data['CLASSIFICATION'].value_counts()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"pbnORE4UQHuu","outputId":"0f05774f-e586-413f-c5a0-e6d838e3e803","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645752259064,"user_tz":480,"elapsed":2,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["C1000    17326\n","C2000     6074\n","C1200     4837\n","C3000     1918\n","C2100     1883\n","C7000      777\n","C1700      287\n","C4000      194\n","C5000      116\n","C1270      114\n","C2700      104\n","C2800       95\n","C7100       75\n","C1300       58\n","C1280       50\n","C1230       36\n","C1400       34\n","C7200       32\n","C2300       32\n","C1240       30\n","C8000       20\n","C7120       18\n","C1500       16\n","C1800       15\n","C6000       15\n","C1250       14\n","C8200       11\n","C1238       10\n","C1278       10\n","C1235        9\n","C1237        9\n","C7210        7\n","C2400        6\n","C1720        6\n","C4100        6\n","C1257        5\n","C1600        5\n","C1260        3\n","C2710        3\n","C0           3\n","C3200        2\n","C1234        2\n","C1246        2\n","C1267        2\n","C1256        2\n","Name: CLASSIFICATION, dtype: int64"]},"metadata":{},"execution_count":9}],"source":["# You may find it helpful to look at CLASSIFICATION value counts >1\n","more_than_one = data['CLASSIFICATION'].value_counts().loc[lambda x : x>1]\n","more_than_one"]},{"cell_type":"code","source":["grouped = data['CLASSIFICATION'].value_counts().loc[lambda x : x < 50]\n","grouped"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aLsJ0Rfq1mMi","executionInfo":{"status":"ok","timestamp":1645752260511,"user_tz":480,"elapsed":134,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"63fdac74-b456-40ac-d1b8-c1dc550cb7c2"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["C1230    36\n","C1400    34\n","C7200    32\n","C2300    32\n","C1240    30\n","C8000    20\n","C7120    18\n","C1500    16\n","C1800    15\n","C6000    15\n","C1250    14\n","C8200    11\n","C1238    10\n","C1278    10\n","C1235     9\n","C1237     9\n","C7210     7\n","C2400     6\n","C1720     6\n","C4100     6\n","C1257     5\n","C1600     5\n","C1260     3\n","C2710     3\n","C0        3\n","C3200     2\n","C1234     2\n","C1246     2\n","C1267     2\n","C1256     2\n","C2190     1\n","C4200     1\n","C2600     1\n","C5200     1\n","C1370     1\n","C1248     1\n","C6100     1\n","C1820     1\n","C1900     1\n","C1236     1\n","C3700     1\n","C2570     1\n","C1580     1\n","C1245     1\n","C2500     1\n","C1570     1\n","C1283     1\n","C2380     1\n","C1732     1\n","C1728     1\n","C2170     1\n","C4120     1\n","C8210     1\n","C2561     1\n","C4500     1\n","C2150     1\n","Name: CLASSIFICATION, dtype: int64"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","execution_count":11,"metadata":{"id":"zOgHEr6AQHuu","outputId":"47f1a0ab-fb12-473b-f85e-1c398e8fb343","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645752261521,"user_tz":480,"elapsed":476,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["C1000    17326\n","C2000     6074\n","C1200     4837\n","C3000     1918\n","C2100     1883\n","C7000      777\n","Other      391\n","C1700      287\n","C4000      194\n","C5000      116\n","C1270      114\n","C2700      104\n","C2800       95\n","C7100       75\n","C1300       58\n","C1280       50\n","Name: CLASSIFICATION, dtype: int64"]},"metadata":{},"execution_count":11}],"source":["# Choose a cutoff value and create a list of classifications to be replaced\n","# use the variable name `classifications_to_replace`\n","classifications_to_replace = grouped.index.to_list()\n","# Replace in dataframe\n","for cls in classifications_to_replace:\n","    data['CLASSIFICATION'] = data['CLASSIFICATION'].replace(cls,\"Other\")\n","    \n","# Check to make sure binning was successful\n","data['CLASSIFICATION'].value_counts()"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"Wy9TAnqiQHuv","executionInfo":{"status":"ok","timestamp":1645752261830,"user_tz":480,"elapsed":128,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"outputs":[],"source":["# Convert categorical data to numeric with `pd.get_dummies`\n","data = pd.get_dummies(data)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"9O0hZHEAQHuv","executionInfo":{"status":"ok","timestamp":1645752262350,"user_tz":480,"elapsed":2,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"outputs":[],"source":["# Split our preprocessed data into our features and target arrays\n","X = data.drop(columns = ['IS_SUCCESSFUL'])\n","y = data['IS_SUCCESSFUL']\n","# Split the preprocessed data into a training and testing dataset\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"jGy0HP0rQHuv","executionInfo":{"status":"ok","timestamp":1645752263016,"user_tz":480,"elapsed":175,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"outputs":[],"source":["# Create a StandardScaler instances\n","scaler = StandardScaler()\n","\n","# Fit the StandardScaler\n","X_scaler = scaler.fit(X_train)\n","\n","# Scale the data\n","X_train_scaled = X_scaler.transform(X_train)\n","X_test_scaled = X_scaler.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"RcJqrI1iQHuw"},"source":["## Compile, Train and Evaluate the Model"]},{"cell_type":"code","source":["# check how many inputs we have\n","X.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qJvLolR2BrRb","executionInfo":{"status":"ok","timestamp":1645752265121,"user_tz":480,"elapsed":2,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"fc2a766d-3c58-48d9-a44c-8558c729b988"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(34299, 55)"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","execution_count":16,"metadata":{"id":"FKqRR7vgQHuw","outputId":"ef28606a-90da-4422-bb77-07f843cc6777","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645752267689,"user_tz":480,"elapsed":652,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 25)                1400      \n","                                                                 \n"," dense_1 (Dense)             (None, 25)                650       \n","                                                                 \n"," dense_2 (Dense)             (None, 1)                 26        \n","                                                                 \n","=================================================================\n","Total params: 2,076\n","Trainable params: 2,076\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n","nn_model = tf.keras.models.Sequential()\n","\n","# hidden layers\n","nn_model.add(tf.keras.layers.Dense(units=25, activation=\"relu\", input_dim=55))\n","nn_model.add(tf.keras.layers.Dense(units=25, activation=\"relu\"))\n","\n","# output layer\n","nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","# Check the structure of the model\n","nn_model.summary()"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"fKTDHRwlQHuw","executionInfo":{"status":"ok","timestamp":1645752268683,"user_tz":480,"elapsed":145,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"outputs":[],"source":["# Compile the model\n","nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"]},{"cell_type":"code","source":["from tensorflow.keras.callbacks import ModelCheckpoint\n","checkpoint_path = 'model_checkpoints/'\n","checkpoint = ModelCheckpoint(\n","    filepath=checkpoint_path,\n","    save_freq=5,\n","    save_weights_only=True\n","    )"],"metadata":{"id":"sNTUhX1NJFyf","executionInfo":{"status":"ok","timestamp":1645752269726,"user_tz":480,"elapsed":124,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","execution_count":19,"metadata":{"id":"A9bnizyAQHuw","outputId":"e006d1c2-c0e6-40fa-aebd-63826b89b00d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645752619040,"user_tz":480,"elapsed":346412,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5769 - accuracy: 0.7148\n","Epoch 2/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5537 - accuracy: 0.7302\n","Epoch 3/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5501 - accuracy: 0.7290\n","Epoch 4/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5473 - accuracy: 0.7320\n","Epoch 5/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5459 - accuracy: 0.7326\n","Epoch 6/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5451 - accuracy: 0.7335\n","Epoch 7/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5438 - accuracy: 0.7336\n","Epoch 8/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5430 - accuracy: 0.7345\n","Epoch 9/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5425 - accuracy: 0.7352\n","Epoch 10/100\n","804/804 [==============================] - 5s 6ms/step - loss: 0.5422 - accuracy: 0.7345\n","Epoch 11/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5414 - accuracy: 0.7359\n","Epoch 12/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5410 - accuracy: 0.7358\n","Epoch 13/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5405 - accuracy: 0.7364\n","Epoch 14/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5403 - accuracy: 0.7372\n","Epoch 15/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5402 - accuracy: 0.7367\n","Epoch 16/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5393 - accuracy: 0.7378\n","Epoch 17/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5390 - accuracy: 0.7378\n","Epoch 18/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5386 - accuracy: 0.7385\n","Epoch 19/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5381 - accuracy: 0.7388\n","Epoch 20/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5379 - accuracy: 0.7398\n","Epoch 21/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5378 - accuracy: 0.7390\n","Epoch 22/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5374 - accuracy: 0.7388\n","Epoch 23/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5374 - accuracy: 0.7389\n","Epoch 24/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5371 - accuracy: 0.7393\n","Epoch 25/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5369 - accuracy: 0.7389\n","Epoch 26/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5364 - accuracy: 0.7392\n","Epoch 27/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5364 - accuracy: 0.7402\n","Epoch 28/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5362 - accuracy: 0.7388\n","Epoch 29/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5359 - accuracy: 0.7404\n","Epoch 30/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5362 - accuracy: 0.7396\n","Epoch 31/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5357 - accuracy: 0.7400\n","Epoch 32/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5351 - accuracy: 0.7399\n","Epoch 33/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5351 - accuracy: 0.7400\n","Epoch 34/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5352 - accuracy: 0.7407\n","Epoch 35/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5349 - accuracy: 0.7399\n","Epoch 36/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5346 - accuracy: 0.7402\n","Epoch 37/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5347 - accuracy: 0.7416\n","Epoch 38/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5343 - accuracy: 0.7404\n","Epoch 39/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5344 - accuracy: 0.7407\n","Epoch 40/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5343 - accuracy: 0.7418\n","Epoch 41/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5341 - accuracy: 0.7399\n","Epoch 42/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5339 - accuracy: 0.7408\n","Epoch 43/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5338 - accuracy: 0.7398\n","Epoch 44/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5340 - accuracy: 0.7413\n","Epoch 45/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5336 - accuracy: 0.7416\n","Epoch 46/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5338 - accuracy: 0.7411\n","Epoch 47/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5333 - accuracy: 0.7415\n","Epoch 48/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5334 - accuracy: 0.7414\n","Epoch 49/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5331 - accuracy: 0.7397\n","Epoch 50/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5330 - accuracy: 0.7406\n","Epoch 51/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5333 - accuracy: 0.7410\n","Epoch 52/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5330 - accuracy: 0.7408\n","Epoch 53/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5333 - accuracy: 0.7402\n","Epoch 54/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5328 - accuracy: 0.7413\n","Epoch 55/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5330 - accuracy: 0.7416\n","Epoch 56/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5327 - accuracy: 0.7422\n","Epoch 57/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5330 - accuracy: 0.7420\n","Epoch 58/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5325 - accuracy: 0.7417\n","Epoch 59/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5324 - accuracy: 0.7423\n","Epoch 60/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5321 - accuracy: 0.7423\n","Epoch 61/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5322 - accuracy: 0.7421\n","Epoch 62/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5325 - accuracy: 0.7420\n","Epoch 63/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5321 - accuracy: 0.7429\n","Epoch 64/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5322 - accuracy: 0.7421\n","Epoch 65/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5321 - accuracy: 0.7423\n","Epoch 66/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5318 - accuracy: 0.7420\n","Epoch 67/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5319 - accuracy: 0.7418\n","Epoch 68/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5317 - accuracy: 0.7414\n","Epoch 69/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5315 - accuracy: 0.7428\n","Epoch 70/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5318 - accuracy: 0.7415\n","Epoch 71/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5314 - accuracy: 0.7428\n","Epoch 72/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5316 - accuracy: 0.7430\n","Epoch 73/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5311 - accuracy: 0.7424\n","Epoch 74/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5314 - accuracy: 0.7423\n","Epoch 75/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5315 - accuracy: 0.7432\n","Epoch 76/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5314 - accuracy: 0.7418\n","Epoch 77/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5316 - accuracy: 0.7425\n","Epoch 78/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5311 - accuracy: 0.7419\n","Epoch 79/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5310 - accuracy: 0.7421\n","Epoch 80/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5316 - accuracy: 0.7423\n","Epoch 81/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5310 - accuracy: 0.7430\n","Epoch 82/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5312 - accuracy: 0.7424\n","Epoch 83/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5308 - accuracy: 0.7427\n","Epoch 84/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5309 - accuracy: 0.7434\n","Epoch 85/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5309 - accuracy: 0.7420\n","Epoch 86/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5305 - accuracy: 0.7435\n","Epoch 87/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5310 - accuracy: 0.7434\n","Epoch 88/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5302 - accuracy: 0.7442\n","Epoch 89/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5301 - accuracy: 0.7425\n","Epoch 90/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5306 - accuracy: 0.7429\n","Epoch 91/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5303 - accuracy: 0.7429\n","Epoch 92/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5307 - accuracy: 0.7434\n","Epoch 93/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5309 - accuracy: 0.7435\n","Epoch 94/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5301 - accuracy: 0.7428\n","Epoch 95/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5302 - accuracy: 0.7422\n","Epoch 96/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5303 - accuracy: 0.7437\n","Epoch 97/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5302 - accuracy: 0.7431\n","Epoch 98/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5302 - accuracy: 0.7429\n","Epoch 99/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5301 - accuracy: 0.7434\n","Epoch 100/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5299 - accuracy: 0.7435\n"]}],"source":["# Train the model\n","fit_model = nn_model.fit(X_train_scaled, y_train, epochs = 100, callbacks = [checkpoint])"]},{"cell_type":"code","source":[""],"metadata":{"id":"rrXE5Ss7IuAE"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":20,"metadata":{"id":"YpPOR3ZLQHuw","outputId":"f2059931-7c88-4ad4-ca87-ac1f3a3f473d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645752927507,"user_tz":480,"elapsed":650,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["268/268 - 0s - loss: 0.5769 - accuracy: 0.7259 - 429ms/epoch - 2ms/step\n","Loss: 0.5768680572509766, Accuracy: 0.7259474992752075\n"]}],"source":["# Evaluate the model using the test data\n","model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n","print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"iy_CNitaQHuw","executionInfo":{"status":"ok","timestamp":1645752930349,"user_tz":480,"elapsed":377,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"outputs":[],"source":["# Export our model to HDF5 file\n","nn_model.save(\"/content/drive/My Drive/ML_Colab/21-Deep-Learning/Homework/Instructions/AlphabetSoupCharity.h5\") "]},{"cell_type":"markdown","source":["OPTIMIZING THE MODEL -- EXPERIMENTATION (FINALIZED HYPERPARAMETER SETTINGS CAN BE FOUND IN THE ADJACENT NOTEBOOK)"],"metadata":{"id":"p-a0yvpJMhRx"}},{"cell_type":"code","source":["# try to optimize so that accuracy exceeds the .75 target. Per the previous cellblock, accuracy currently stands at 0.726"],"metadata":{"id":"jzIQwoB_MjKO","executionInfo":{"status":"ok","timestamp":1645752938363,"user_tz":480,"elapsed":147,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# set up tuner to optimize model\n","\n","def create_model(hp):\n","    nn_model_opt = tf.keras.models.Sequential()\n","\n","    # Allow kerastuner to decide which activation function to use in hidden layers\n","    activation = hp.Choice('activation',['relu','tanh'])\n","    \n","    # Allow kerastuner to decide number of neurons in first layer\n","    nn_model_opt.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n","        min_value=1,\n","        max_value=50,\n","        step=2), activation=activation, input_dim=55))\n","\n","    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n","    for i in range(hp.Int('num_layers', 1, 50)):\n","        nn_model_opt.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n","            min_value=1,\n","            max_value=50,\n","            step=2),\n","            activation=activation))\n","    \n","    nn_model_opt.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","    # Compile the model\n","    nn_model_opt.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n","    \n","    return nn_model_opt"],"metadata":{"id":"IPUYuTWhNYoW","executionInfo":{"status":"ok","timestamp":1645752940382,"user_tz":480,"elapsed":151,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Import the kerastuner library\n","!pip install -q -U keras-tuner\n","import keras_tuner as kt\n","\n","tuner = kt.Hyperband(\n","    create_model,\n","    objective=\"val_accuracy\",\n","    max_epochs=20,\n","    overwrite = True,\n","    hyperband_iterations=2)"],"metadata":{"id":"4agrB7yE5lOK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645752946052,"user_tz":480,"elapsed":4438,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"7d890b85-a001-47d0-d712-d2d3dbd6e062"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 19.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 51 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 71 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 92 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 98 kB 3.7 MB/s \n","\u001b[?25h"]}]},{"cell_type":"code","source":["# Run the kerastuner search for best hyperparameters\n","tuner.search(X_train_scaled,y_train,epochs=20,validation_data=(X_test_scaled,y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dLBJy6lA5p3z","outputId":"618f0c04-5c09-4b15-d7de-448aed937c21","executionInfo":{"status":"ok","timestamp":1645755030805,"user_tz":480,"elapsed":2083118,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 60 Complete [00h 01m 14s]\n","val_accuracy: 0.5255976915359497\n","\n","Best val_accuracy So Far: 0.7297959327697754\n","Total elapsed time: 00h 34m 43s\n","INFO:tensorflow:Oracle triggered exit\n"]}]},{"cell_type":"code","source":["# Get top 3 model hyperparameters and print the values\n","top_hyper = tuner.get_best_hyperparameters(3)\n","for param in top_hyper:\n","    print(param.values)"],"metadata":{"id":"VdwR0B0S54QY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645755066162,"user_tz":480,"elapsed":243,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"fceaf5c2-748c-45d7-f5ef-902d5bfa4816"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["{'activation': 'tanh', 'first_units': 29, 'num_layers': 8, 'units_0': 25, 'units_1': 25, 'units_2': 45, 'units_3': 37, 'units_4': 19, 'units_5': 5, 'units_6': 29, 'units_7': 47, 'units_8': 11, 'units_9': 21, 'units_10': 45, 'units_11': 27, 'units_12': 13, 'units_13': 17, 'units_14': 5, 'units_15': 31, 'units_16': 15, 'units_17': 47, 'units_18': 31, 'units_19': 15, 'units_20': 15, 'units_21': 25, 'units_22': 37, 'units_23': 13, 'units_24': 35, 'units_25': 27, 'units_26': 45, 'units_27': 21, 'units_28': 3, 'units_29': 31, 'units_30': 47, 'units_31': 41, 'units_32': 43, 'units_33': 49, 'units_34': 1, 'units_35': 27, 'units_36': 41, 'units_37': 17, 'units_38': 17, 'units_39': 39, 'units_40': 31, 'units_41': 43, 'units_42': 43, 'units_43': 3, 'units_44': 37, 'units_45': 17, 'units_46': 17, 'units_47': 7, 'units_48': 1, 'tuner/epochs': 20, 'tuner/initial_epoch': 7, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': '2122976eb7d0f3a10944fad30d6274f3'}\n","{'activation': 'tanh', 'first_units': 33, 'num_layers': 6, 'units_0': 33, 'units_1': 37, 'units_2': 47, 'units_3': 17, 'units_4': 39, 'units_5': 1, 'units_6': 27, 'units_7': 47, 'units_8': 29, 'units_9': 47, 'units_10': 35, 'units_11': 7, 'units_12': 5, 'units_13': 37, 'units_14': 25, 'units_15': 27, 'units_16': 15, 'units_17': 45, 'units_18': 11, 'units_19': 29, 'units_20': 9, 'units_21': 5, 'units_22': 33, 'units_23': 29, 'units_24': 37, 'units_25': 11, 'units_26': 37, 'units_27': 37, 'units_28': 11, 'units_29': 5, 'units_30': 41, 'units_31': 15, 'units_32': 23, 'units_33': 9, 'units_34': 39, 'units_35': 37, 'units_36': 25, 'units_37': 39, 'units_38': 13, 'units_39': 27, 'units_40': 5, 'units_41': 35, 'units_42': 13, 'units_43': 39, 'units_44': 31, 'units_45': 25, 'units_46': 23, 'units_47': 29, 'units_48': 7, 'tuner/epochs': 20, 'tuner/initial_epoch': 7, 'tuner/bracket': 2, 'tuner/round': 2, 'tuner/trial_id': 'faa6617c6a99d16dfc4ffd6d3d5904f9'}\n","{'activation': 'tanh', 'first_units': 33, 'num_layers': 6, 'units_0': 33, 'units_1': 37, 'units_2': 47, 'units_3': 17, 'units_4': 39, 'units_5': 1, 'units_6': 27, 'units_7': 47, 'units_8': 29, 'units_9': 47, 'units_10': 35, 'units_11': 7, 'units_12': 5, 'units_13': 37, 'units_14': 25, 'units_15': 27, 'units_16': 15, 'units_17': 45, 'units_18': 11, 'units_19': 29, 'units_20': 9, 'units_21': 5, 'units_22': 33, 'units_23': 29, 'units_24': 37, 'units_25': 11, 'units_26': 37, 'units_27': 37, 'units_28': 11, 'units_29': 5, 'units_30': 41, 'units_31': 15, 'units_32': 23, 'units_33': 9, 'units_34': 39, 'units_35': 37, 'units_36': 25, 'units_37': 39, 'units_38': 13, 'units_39': 27, 'units_40': 5, 'units_41': 35, 'units_42': 13, 'units_43': 39, 'units_44': 31, 'units_45': 25, 'units_46': 23, 'units_47': 29, 'units_48': 7, 'tuner/epochs': 3, 'tuner/initial_epoch': 0, 'tuner/bracket': 2, 'tuner/round': 0}\n"]}]},{"cell_type":"code","source":["# Evaluate the top 3 models against the test dataset\n","top_model = tuner.get_best_models(3)\n","for model in top_model:\n","    model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n","    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"],"metadata":{"id":"YccChybO557Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645755069682,"user_tz":480,"elapsed":3168,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"2f2ab3b6-a6e7-4f07-cbd7-ef0158f23dee"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["268/268 - 1s - loss: 0.5532 - accuracy: 0.7298 - 602ms/epoch - 2ms/step\n","Loss: 0.5531752705574036, Accuracy: 0.7297959327697754\n","268/268 - 1s - loss: 0.5663 - accuracy: 0.7282 - 561ms/epoch - 2ms/step\n","Loss: 0.5663350224494934, Accuracy: 0.7281632423400879\n","268/268 - 1s - loss: 0.5700 - accuracy: 0.7279 - 526ms/epoch - 2ms/step\n","Loss: 0.569952130317688, Accuracy: 0.7279300093650818\n"]}]},{"cell_type":"code","source":["# We can see that the best validation accuracy os far (from above) is 0.73. It may be useful to check if there are outliers in the data that can be removed...\n","import matplotlib.pyplot as plt\n","\n","plt.figure(figsize = (20,20))\n","plt.boxplot(data['ASK_AMT'])\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"cOPa5rwHDxIO","executionInfo":{"status":"ok","timestamp":1645755072900,"user_tz":480,"elapsed":504,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"6a3d0c88-dfe1-43de-baa1-b955a4c1a46a"},"execution_count":28,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 1440x1440 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["# finding the 1st quartile\n","import numpy as np\n","q1 = np.quantile(data['ASK_AMT'], 0.25)\n"," \n","# finding the 3rd quartile\n","q3 = np.quantile(data['ASK_AMT'], 0.75)\n","med = np.median(data['ASK_AMT'])\n"," \n","# finding the iqr region\n","iqr = q3-q1\n"," \n","# finding upper and lower whiskers\n","upper_bound = q3+(1.5*iqr)\n","lower_bound = q1-(1.5*iqr)\n","print(iqr, upper_bound, lower_bound)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ztio5__MQw4","executionInfo":{"status":"ok","timestamp":1645755077026,"user_tz":480,"elapsed":123,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"dfb3f614-a19e-47ce-bde5-e959c6da2904"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["2742.0 11855.0 887.0\n"]}]},{"cell_type":"code","source":["data['ASK_AMT'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AKyWujal57-Z","executionInfo":{"status":"ok","timestamp":1645755077451,"user_tz":480,"elapsed":3,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"12396fa1-04a9-4de6-9785-9faff03fcf38"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5000        25398\n","10478           3\n","15583           3\n","63981           3\n","6725            3\n","            ...  \n","5371754         1\n","30060           1\n","43091152        1\n","18683           1\n","36500179        1\n","Name: ASK_AMT, Length: 8747, dtype: int64"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["rare_amts = data['ASK_AMT'].value_counts().loc[lambda x : x ==1]\n","rare_amts.sort_index()\n","# rare_amts.sort_index(ascending = True).index.to_list()\n","# rare_amts.sort_index(ascending = False).index.to_list()\n","# there appear to be a handful of applications that only occur once and have request amounts that exceed 1 billion. Let's try removing them to see if that can improve model performance"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-j-Qw5-mDynl","executionInfo":{"status":"ok","timestamp":1645755081659,"user_tz":480,"elapsed":128,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"745d3e52-c13d-4556-c9a6-552ec548049f"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5001          1\n","5016          1\n","5037          1\n","5040          1\n","5044          1\n","             ..\n","3391919220    1\n","4653011914    1\n","5591584994    1\n","8556638692    1\n","8597806340    1\n","Name: ASK_AMT, Length: 8595, dtype: int64"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["data = data.loc[data['ASK_AMT'] < 1000000000]\n","data"],"metadata":{"id":"aWL_ZQASFfOI","colab":{"base_uri":"https://localhost:8080/","height":505},"executionInfo":{"status":"ok","timestamp":1645755081961,"user_tz":480,"elapsed":149,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"5a2f112f-fdc2-4b87-d44c-f56b5a04d655"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-0576ef0d-a299-48e9-af08-6db7cc0147ac\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>STATUS</th>\n","      <th>ASK_AMT</th>\n","      <th>IS_SUCCESSFUL</th>\n","      <th>APPLICATION_TYPE_Other</th>\n","      <th>APPLICATION_TYPE_T10</th>\n","      <th>APPLICATION_TYPE_T13</th>\n","      <th>APPLICATION_TYPE_T19</th>\n","      <th>APPLICATION_TYPE_T3</th>\n","      <th>APPLICATION_TYPE_T4</th>\n","      <th>APPLICATION_TYPE_T5</th>\n","      <th>APPLICATION_TYPE_T6</th>\n","      <th>APPLICATION_TYPE_T7</th>\n","      <th>APPLICATION_TYPE_T8</th>\n","      <th>APPLICATION_TYPE_T9</th>\n","      <th>AFFILIATION_CompanySponsored</th>\n","      <th>AFFILIATION_Family/Parent</th>\n","      <th>AFFILIATION_Independent</th>\n","      <th>AFFILIATION_National</th>\n","      <th>AFFILIATION_Other</th>\n","      <th>AFFILIATION_Regional</th>\n","      <th>CLASSIFICATION_C1000</th>\n","      <th>CLASSIFICATION_C1200</th>\n","      <th>CLASSIFICATION_C1270</th>\n","      <th>CLASSIFICATION_C1280</th>\n","      <th>CLASSIFICATION_C1300</th>\n","      <th>CLASSIFICATION_C1700</th>\n","      <th>CLASSIFICATION_C2000</th>\n","      <th>CLASSIFICATION_C2100</th>\n","      <th>CLASSIFICATION_C2700</th>\n","      <th>CLASSIFICATION_C2800</th>\n","      <th>CLASSIFICATION_C3000</th>\n","      <th>CLASSIFICATION_C4000</th>\n","      <th>CLASSIFICATION_C5000</th>\n","      <th>CLASSIFICATION_C7000</th>\n","      <th>CLASSIFICATION_C7100</th>\n","      <th>CLASSIFICATION_Other</th>\n","      <th>USE_CASE_CommunityServ</th>\n","      <th>USE_CASE_Heathcare</th>\n","      <th>USE_CASE_Other</th>\n","      <th>USE_CASE_Preservation</th>\n","      <th>USE_CASE_ProductDev</th>\n","      <th>ORGANIZATION_Association</th>\n","      <th>ORGANIZATION_Co-operative</th>\n","      <th>ORGANIZATION_Corporation</th>\n","      <th>ORGANIZATION_Trust</th>\n","      <th>INCOME_AMT_0</th>\n","      <th>INCOME_AMT_1-9999</th>\n","      <th>INCOME_AMT_10000-24999</th>\n","      <th>INCOME_AMT_100000-499999</th>\n","      <th>INCOME_AMT_10M-50M</th>\n","      <th>INCOME_AMT_1M-5M</th>\n","      <th>INCOME_AMT_25000-99999</th>\n","      <th>INCOME_AMT_50M+</th>\n","      <th>INCOME_AMT_5M-10M</th>\n","      <th>SPECIAL_CONSIDERATIONS_N</th>\n","      <th>SPECIAL_CONSIDERATIONS_Y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>108590</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>6692</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>142590</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>34294</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34295</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34296</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34297</th>\n","      <td>1</td>\n","      <td>5000</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>34298</th>\n","      <td>1</td>\n","      <td>36500179</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>34281 rows × 56 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0576ef0d-a299-48e9-af08-6db7cc0147ac')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0576ef0d-a299-48e9-af08-6db7cc0147ac button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0576ef0d-a299-48e9-af08-6db7cc0147ac');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["       STATUS   ASK_AMT  ...  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y\n","0           1      5000  ...                         1                         0\n","1           1    108590  ...                         1                         0\n","2           1      5000  ...                         1                         0\n","3           1      6692  ...                         1                         0\n","4           1    142590  ...                         1                         0\n","...       ...       ...  ...                       ...                       ...\n","34294       1      5000  ...                         1                         0\n","34295       1      5000  ...                         1                         0\n","34296       1      5000  ...                         1                         0\n","34297       1      5000  ...                         1                         0\n","34298       1  36500179  ...                         1                         0\n","\n","[34281 rows x 56 columns]"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["# Now let's try optimizing the model again\n","\n","# Split our preprocessed data into our features and target arrays again\n","X = data.drop(columns = ['IS_SUCCESSFUL'])\n","y = data['IS_SUCCESSFUL']\n","\n","# Split the preprocessed data into a training and testing dataset again\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"],"metadata":{"id":"GAyByGnNHmsO","executionInfo":{"status":"ok","timestamp":1645755084018,"user_tz":480,"elapsed":117,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Create a StandardScaler instances\n","scaler = StandardScaler()\n","\n","# Fit the StandardScaler\n","X_scaler = scaler.fit(X_train)\n","\n","# Scale the data\n","X_train_scaled = X_scaler.transform(X_train)\n","X_test_scaled = X_scaler.transform(X_test)\n"],"metadata":{"id":"qULeWkfvDILq","executionInfo":{"status":"ok","timestamp":1645755084316,"user_tz":480,"elapsed":159,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["#refit the model to new data\n","fit_model = nn_model.fit(X_train_scaled, y_train, epochs = 100, callbacks = [checkpoint])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KlOeXgITxJtL","executionInfo":{"status":"ok","timestamp":1645755480771,"user_tz":480,"elapsed":396143,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"4166289a-d42e-4f29-ab6d-00e23683e4da"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5403 - accuracy: 0.7373\n","Epoch 2/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5358 - accuracy: 0.7382\n","Epoch 3/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5355 - accuracy: 0.7382\n","Epoch 4/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5344 - accuracy: 0.7386\n","Epoch 5/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5345 - accuracy: 0.7388\n","Epoch 6/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5338 - accuracy: 0.7385\n","Epoch 7/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5339 - accuracy: 0.7384\n","Epoch 8/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5339 - accuracy: 0.7375\n","Epoch 9/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5336 - accuracy: 0.7394\n","Epoch 10/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5333 - accuracy: 0.7404\n","Epoch 11/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5332 - accuracy: 0.7393\n","Epoch 12/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5331 - accuracy: 0.7398\n","Epoch 13/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5326 - accuracy: 0.7403\n","Epoch 14/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5329 - accuracy: 0.7396\n","Epoch 15/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5343 - accuracy: 0.7394\n","Epoch 16/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5326 - accuracy: 0.7402\n","Epoch 17/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5324 - accuracy: 0.7395\n","Epoch 18/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5324 - accuracy: 0.7401\n","Epoch 19/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5322 - accuracy: 0.7387\n","Epoch 20/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5318 - accuracy: 0.7393\n","Epoch 21/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5325 - accuracy: 0.7398\n","Epoch 22/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5328 - accuracy: 0.7396\n","Epoch 23/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5318 - accuracy: 0.7388\n","Epoch 24/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5318 - accuracy: 0.7392\n","Epoch 25/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5317 - accuracy: 0.7395\n","Epoch 26/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5317 - accuracy: 0.7397\n","Epoch 27/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5317 - accuracy: 0.7412\n","Epoch 28/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5319 - accuracy: 0.7391\n","Epoch 29/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5317 - accuracy: 0.7398\n","Epoch 30/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5311 - accuracy: 0.7397\n","Epoch 31/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5315 - accuracy: 0.7404\n","Epoch 32/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5316 - accuracy: 0.7400\n","Epoch 33/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5313 - accuracy: 0.7393\n","Epoch 34/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5317 - accuracy: 0.7402\n","Epoch 35/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5312 - accuracy: 0.7405\n","Epoch 36/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5309 - accuracy: 0.7408\n","Epoch 37/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5311 - accuracy: 0.7392\n","Epoch 38/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5312 - accuracy: 0.7395\n","Epoch 39/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5308 - accuracy: 0.7397\n","Epoch 40/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5307 - accuracy: 0.7410\n","Epoch 41/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5310 - accuracy: 0.7398\n","Epoch 42/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5311 - accuracy: 0.7403\n","Epoch 43/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5310 - accuracy: 0.7392\n","Epoch 44/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5306 - accuracy: 0.7394\n","Epoch 45/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5305 - accuracy: 0.7403\n","Epoch 46/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5308 - accuracy: 0.7396\n","Epoch 47/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5309 - accuracy: 0.7404\n","Epoch 48/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5304 - accuracy: 0.7412\n","Epoch 49/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5307 - accuracy: 0.7403\n","Epoch 50/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5309 - accuracy: 0.7405\n","Epoch 51/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5302 - accuracy: 0.7396\n","Epoch 52/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5305 - accuracy: 0.7404\n","Epoch 53/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5306 - accuracy: 0.7414\n","Epoch 54/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5303 - accuracy: 0.7398\n","Epoch 55/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5304 - accuracy: 0.7410\n","Epoch 56/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5305 - accuracy: 0.7397\n","Epoch 57/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5301 - accuracy: 0.7410\n","Epoch 58/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5306 - accuracy: 0.7398\n","Epoch 59/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5305 - accuracy: 0.7399\n","Epoch 60/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5303 - accuracy: 0.7403\n","Epoch 61/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5302 - accuracy: 0.7406\n","Epoch 62/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5305 - accuracy: 0.7401\n","Epoch 63/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5302 - accuracy: 0.7399\n","Epoch 64/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5301 - accuracy: 0.7404\n","Epoch 65/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5302 - accuracy: 0.7411\n","Epoch 66/100\n","804/804 [==============================] - 7s 8ms/step - loss: 0.5302 - accuracy: 0.7402\n","Epoch 67/100\n","804/804 [==============================] - 6s 8ms/step - loss: 0.5299 - accuracy: 0.7414\n","Epoch 68/100\n","804/804 [==============================] - 5s 6ms/step - loss: 0.5305 - accuracy: 0.7399\n","Epoch 69/100\n","804/804 [==============================] - 4s 6ms/step - loss: 0.5303 - accuracy: 0.7406\n","Epoch 70/100\n","804/804 [==============================] - 5s 6ms/step - loss: 0.5300 - accuracy: 0.7411\n","Epoch 71/100\n","804/804 [==============================] - 9s 11ms/step - loss: 0.5297 - accuracy: 0.7413\n","Epoch 72/100\n","804/804 [==============================] - 8s 9ms/step - loss: 0.5298 - accuracy: 0.7409\n","Epoch 73/100\n","804/804 [==============================] - 9s 11ms/step - loss: 0.5300 - accuracy: 0.7408\n","Epoch 74/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5300 - accuracy: 0.7410\n","Epoch 75/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5298 - accuracy: 0.7401\n","Epoch 76/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5303 - accuracy: 0.7403\n","Epoch 77/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5296 - accuracy: 0.7412\n","Epoch 78/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5299 - accuracy: 0.7413\n","Epoch 79/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5298 - accuracy: 0.7410\n","Epoch 80/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5302 - accuracy: 0.7413\n","Epoch 81/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5297 - accuracy: 0.7409\n","Epoch 82/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5299 - accuracy: 0.7406\n","Epoch 83/100\n","804/804 [==============================] - 5s 7ms/step - loss: 0.5294 - accuracy: 0.7414\n","Epoch 84/100\n","804/804 [==============================] - 6s 7ms/step - loss: 0.5295 - accuracy: 0.7411\n","Epoch 85/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5298 - accuracy: 0.7406\n","Epoch 86/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5294 - accuracy: 0.7413\n","Epoch 87/100\n","804/804 [==============================] - 6s 7ms/step - loss: 0.5295 - accuracy: 0.7407\n","Epoch 88/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5293 - accuracy: 0.7406\n","Epoch 89/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5295 - accuracy: 0.7409\n","Epoch 90/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5294 - accuracy: 0.7420\n","Epoch 91/100\n","804/804 [==============================] - 3s 4ms/step - loss: 0.5294 - accuracy: 0.7401\n","Epoch 92/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5294 - accuracy: 0.7415\n","Epoch 93/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5293 - accuracy: 0.7419\n","Epoch 94/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5296 - accuracy: 0.7411\n","Epoch 95/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5292 - accuracy: 0.7408\n","Epoch 96/100\n","804/804 [==============================] - 5s 6ms/step - loss: 0.5292 - accuracy: 0.7407\n","Epoch 97/100\n","804/804 [==============================] - 6s 8ms/step - loss: 0.5293 - accuracy: 0.7408\n","Epoch 98/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5292 - accuracy: 0.7410\n","Epoch 99/100\n","804/804 [==============================] - 4s 4ms/step - loss: 0.5292 - accuracy: 0.7403\n","Epoch 100/100\n","804/804 [==============================] - 4s 5ms/step - loss: 0.5289 - accuracy: 0.7415\n"]}]},{"cell_type":"code","source":["tuner.search(X_train_scaled,y_train,epochs=20,validation_data=(X_test_scaled,y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tjXB4D74SVLe","executionInfo":{"status":"ok","timestamp":1645502719214,"user_tz":480,"elapsed":505457,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"73371c63-f5bf-4fb5-843f-91310c3fd85e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 72 Complete [00h 01m 23s]\n","val_accuracy: 0.7331699728965759\n","\n","Best val_accuracy So Far: 0.735270082950592\n","Total elapsed time: 00h 55m 10s\n","INFO:tensorflow:Oracle triggered exit\n"]}]},{"cell_type":"code","source":["tuner.search(X_train_scaled,y_train,epochs=50,validation_data=(X_test_scaled,y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gxEl8Gk8SXwb","executionInfo":{"status":"ok","timestamp":1645505111890,"user_tz":480,"elapsed":1584912,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"5ea6fd51-303d-46ab-bbb0-f8ed7746a32f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 60 Complete [00h 00m 56s]\n","val_accuracy: 0.7339866757392883\n","\n","Best val_accuracy So Far: 0.7356201410293579\n","Total elapsed time: 00h 26m 24s\n","INFO:tensorflow:Oracle triggered exit\n"]}]},{"cell_type":"code","source":["tuner.search(X_train_scaled,y_train,epochs=50,validation_data=(X_test_scaled,y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qRWnEF9lpPdZ","executionInfo":{"status":"ok","timestamp":1645508140703,"user_tz":480,"elapsed":2159564,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"d201f481-c2c5-4dd7-df3e-04b850c26003"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 60 Complete [00h 01m 26s]\n","val_accuracy: 0.5292264819145203\n","\n","Best val_accuracy So Far: 0.7360867857933044\n","Total elapsed time: 00h 35m 59s\n","INFO:tensorflow:Oracle triggered exit\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Oracle triggered exit\n"]}]},{"cell_type":"code","source":["# cutting out the high-flying outliers, increasing number of epochs and maximum number of neuron layers has improved performance, \n","# but not enough to reach the threshold\n","# let's try playing around with different filters to reduce outliers, but not by too much (cuts too much into the data)\n","new_data = data.loc[data['ASK_AMT'] < 100000]\n","new_data['ASK_AMT'].value_counts().sort_index()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kTQcXxfnwODC","executionInfo":{"status":"ok","timestamp":1645514691949,"user_tz":480,"elapsed":163,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"04e591dc-2fe8-4d7e-c592-3526ad32719a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5000     25398\n","5001         1\n","5006         2\n","5016         1\n","5037         1\n","         ...  \n","99821        1\n","99859        1\n","99877        1\n","99879        1\n","99982        1\n","Name: ASK_AMT, Length: 4230, dtype: int64"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["# Now let's try optimizing the model and experimenting with different hyper parameters again (in the cells to follow)\n","\n","# Split our preprocessed data into our features and target arrays again\n","X = new_data.drop(columns = ['IS_SUCCESSFUL'])\n","y = new_data['IS_SUCCESSFUL']\n","\n","# Split the preprocessed data into a training and testing dataset again\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"],"metadata":{"id":"N3BTJI8k8wVu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Create a StandardScaler instances\n","scaler = StandardScaler()\n","\n","# Fit the StandardScaler\n","X_scaler = scaler.fit(X_train)\n","\n","# Scale the data\n","X_train_scaled = X_scaler.transform(X_train)\n","X_test_scaled = X_scaler.transform(X_test)"],"metadata":{"id":"UdlBogw19945"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#refit the model to new data\n","fit_model = nn_model.fit(X_train_scaled, y_train, epochs = 200, callbacks = [checkpoint])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z7kxPIpS-E9f","executionInfo":{"status":"ok","timestamp":1645515448829,"user_tz":480,"elapsed":742287,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"38906382-5bae-4c98-ea90-8b8d4a4140bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5469 - accuracy: 0.7406\n","Epoch 2/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5305 - accuracy: 0.7444\n","Epoch 3/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5273 - accuracy: 0.7471\n","Epoch 4/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5257 - accuracy: 0.7469\n","Epoch 5/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5241 - accuracy: 0.7474\n","Epoch 6/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5237 - accuracy: 0.7479\n","Epoch 7/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5228 - accuracy: 0.7491\n","Epoch 8/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5230 - accuracy: 0.7491\n","Epoch 9/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5212 - accuracy: 0.7494\n","Epoch 10/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5210 - accuracy: 0.7478\n","Epoch 11/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5204 - accuracy: 0.7492\n","Epoch 12/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5200 - accuracy: 0.7490\n","Epoch 13/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5200 - accuracy: 0.7489\n","Epoch 14/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5200 - accuracy: 0.7499\n","Epoch 15/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5190 - accuracy: 0.7494\n","Epoch 16/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5190 - accuracy: 0.7498\n","Epoch 17/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5186 - accuracy: 0.7502\n","Epoch 18/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5183 - accuracy: 0.7494\n","Epoch 19/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5183 - accuracy: 0.7505\n","Epoch 20/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5180 - accuracy: 0.7504\n","Epoch 21/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5180 - accuracy: 0.7503\n","Epoch 22/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5176 - accuracy: 0.7510\n","Epoch 23/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5175 - accuracy: 0.7502\n","Epoch 24/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5170 - accuracy: 0.7505\n","Epoch 25/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5173 - accuracy: 0.7507\n","Epoch 26/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5181 - accuracy: 0.7504\n","Epoch 27/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5168 - accuracy: 0.7500\n","Epoch 28/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5172 - accuracy: 0.7503\n","Epoch 29/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5172 - accuracy: 0.7509\n","Epoch 30/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5165 - accuracy: 0.7506\n","Epoch 31/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5167 - accuracy: 0.7503\n","Epoch 32/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5163 - accuracy: 0.7504\n","Epoch 33/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5161 - accuracy: 0.7497\n","Epoch 34/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5159 - accuracy: 0.7504\n","Epoch 35/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5161 - accuracy: 0.7505\n","Epoch 36/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5160 - accuracy: 0.7506\n","Epoch 37/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5158 - accuracy: 0.7513\n","Epoch 38/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5158 - accuracy: 0.7512\n","Epoch 39/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5157 - accuracy: 0.7509\n","Epoch 40/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5157 - accuracy: 0.7507\n","Epoch 41/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5158 - accuracy: 0.7515\n","Epoch 42/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5153 - accuracy: 0.7513\n","Epoch 43/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5156 - accuracy: 0.7508\n","Epoch 44/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5153 - accuracy: 0.7512\n","Epoch 45/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5153 - accuracy: 0.7515\n","Epoch 46/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5151 - accuracy: 0.7517\n","Epoch 47/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5156 - accuracy: 0.7511\n","Epoch 48/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5150 - accuracy: 0.7512\n","Epoch 49/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5152 - accuracy: 0.7510\n","Epoch 50/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5158 - accuracy: 0.7513\n","Epoch 51/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5148 - accuracy: 0.7521\n","Epoch 52/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5150 - accuracy: 0.7518\n","Epoch 53/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5148 - accuracy: 0.7525\n","Epoch 54/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5144 - accuracy: 0.7520\n","Epoch 55/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5143 - accuracy: 0.7516\n","Epoch 56/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5146 - accuracy: 0.7514\n","Epoch 57/200\n","698/698 [==============================] - 5s 7ms/step - loss: 0.5149 - accuracy: 0.7523\n","Epoch 58/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5141 - accuracy: 0.7519\n","Epoch 59/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5142 - accuracy: 0.7510\n","Epoch 60/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5145 - accuracy: 0.7525\n","Epoch 61/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5143 - accuracy: 0.7519\n","Epoch 62/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5159 - accuracy: 0.7514\n","Epoch 63/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5135 - accuracy: 0.7514\n","Epoch 64/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5139 - accuracy: 0.7517\n","Epoch 65/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5140 - accuracy: 0.7515\n","Epoch 66/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5138 - accuracy: 0.7519\n","Epoch 67/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5137 - accuracy: 0.7512\n","Epoch 68/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5133 - accuracy: 0.7519\n","Epoch 69/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5141 - accuracy: 0.7527\n","Epoch 70/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5137 - accuracy: 0.7513\n","Epoch 71/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5138 - accuracy: 0.7527\n","Epoch 72/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5134 - accuracy: 0.7522\n","Epoch 73/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5132 - accuracy: 0.7524\n","Epoch 74/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5132 - accuracy: 0.7530\n","Epoch 75/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5135 - accuracy: 0.7525\n","Epoch 76/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5133 - accuracy: 0.7521\n","Epoch 77/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5130 - accuracy: 0.7528\n","Epoch 78/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5129 - accuracy: 0.7528\n","Epoch 79/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5127 - accuracy: 0.7517\n","Epoch 80/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5132 - accuracy: 0.7529\n","Epoch 81/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5127 - accuracy: 0.7523\n","Epoch 82/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5170 - accuracy: 0.7528\n","Epoch 83/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5126 - accuracy: 0.7526\n","Epoch 84/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5129 - accuracy: 0.7527\n","Epoch 85/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5130 - accuracy: 0.7527\n","Epoch 86/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5125 - accuracy: 0.7526\n","Epoch 87/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5123 - accuracy: 0.7522\n","Epoch 88/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5125 - accuracy: 0.7523\n","Epoch 89/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5122 - accuracy: 0.7532\n","Epoch 90/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5121 - accuracy: 0.7534\n","Epoch 91/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5129 - accuracy: 0.7528\n","Epoch 92/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5123 - accuracy: 0.7521\n","Epoch 93/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5125 - accuracy: 0.7527\n","Epoch 94/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5117 - accuracy: 0.7528\n","Epoch 95/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5125 - accuracy: 0.7524\n","Epoch 96/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5120 - accuracy: 0.7523\n","Epoch 97/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5119 - accuracy: 0.7526\n","Epoch 98/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5122 - accuracy: 0.7522\n","Epoch 99/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5146 - accuracy: 0.7526\n","Epoch 100/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5120 - accuracy: 0.7529\n","Epoch 101/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5115 - accuracy: 0.7523\n","Epoch 102/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5119 - accuracy: 0.7516\n","Epoch 103/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5120 - accuracy: 0.7526\n","Epoch 104/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5118 - accuracy: 0.7520\n","Epoch 105/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5118 - accuracy: 0.7526\n","Epoch 106/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5122 - accuracy: 0.7523\n","Epoch 107/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5118 - accuracy: 0.7531\n","Epoch 108/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5117 - accuracy: 0.7525\n","Epoch 109/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5118 - accuracy: 0.7532\n","Epoch 110/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5117 - accuracy: 0.7532\n","Epoch 111/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5132 - accuracy: 0.7528\n","Epoch 112/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5120 - accuracy: 0.7533\n","Epoch 113/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5125 - accuracy: 0.7530\n","Epoch 114/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5110 - accuracy: 0.7533\n","Epoch 115/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5115 - accuracy: 0.7540\n","Epoch 116/200\n","698/698 [==============================] - 3s 5ms/step - loss: 0.5112 - accuracy: 0.7532\n","Epoch 117/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5112 - accuracy: 0.7532\n","Epoch 118/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5125 - accuracy: 0.7533\n","Epoch 119/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5109 - accuracy: 0.7536\n","Epoch 120/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5113 - accuracy: 0.7533\n","Epoch 121/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5108 - accuracy: 0.7525\n","Epoch 122/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5113 - accuracy: 0.7534\n","Epoch 123/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5113 - accuracy: 0.7526\n","Epoch 124/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5111 - accuracy: 0.7535\n","Epoch 125/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5112 - accuracy: 0.7522\n","Epoch 126/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5111 - accuracy: 0.7519\n","Epoch 127/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5104 - accuracy: 0.7538\n","Epoch 128/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5110 - accuracy: 0.7529\n","Epoch 129/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5115 - accuracy: 0.7536\n","Epoch 130/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5114 - accuracy: 0.7533\n","Epoch 131/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5110 - accuracy: 0.7535\n","Epoch 132/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5108 - accuracy: 0.7539\n","Epoch 133/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5111 - accuracy: 0.7530\n","Epoch 134/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5105 - accuracy: 0.7535\n","Epoch 135/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5108 - accuracy: 0.7531\n","Epoch 136/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5108 - accuracy: 0.7532\n","Epoch 137/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5111 - accuracy: 0.7535\n","Epoch 138/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5109 - accuracy: 0.7528\n","Epoch 139/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5105 - accuracy: 0.7525\n","Epoch 140/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5106 - accuracy: 0.7531\n","Epoch 141/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5110 - accuracy: 0.7530\n","Epoch 142/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5106 - accuracy: 0.7527\n","Epoch 143/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5109 - accuracy: 0.7531\n","Epoch 144/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5112 - accuracy: 0.7529\n","Epoch 145/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5103 - accuracy: 0.7538\n","Epoch 146/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5109 - accuracy: 0.7537\n","Epoch 147/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5106 - accuracy: 0.7538\n","Epoch 148/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5105 - accuracy: 0.7535\n","Epoch 149/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5104 - accuracy: 0.7528\n","Epoch 150/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5105 - accuracy: 0.7538\n","Epoch 151/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5103 - accuracy: 0.7532\n","Epoch 152/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5102 - accuracy: 0.7539\n","Epoch 153/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5106 - accuracy: 0.7526\n","Epoch 154/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5127 - accuracy: 0.7532\n","Epoch 155/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5101 - accuracy: 0.7539\n","Epoch 156/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5098 - accuracy: 0.7538\n","Epoch 157/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5106 - accuracy: 0.7537\n","Epoch 158/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5110 - accuracy: 0.7534\n","Epoch 159/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5106 - accuracy: 0.7528\n","Epoch 160/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5103 - accuracy: 0.7531\n","Epoch 161/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5105 - accuracy: 0.7536\n","Epoch 162/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5102 - accuracy: 0.7543\n","Epoch 163/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5105 - accuracy: 0.7528\n","Epoch 164/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5104 - accuracy: 0.7530\n","Epoch 165/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5100 - accuracy: 0.7543\n","Epoch 166/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5103 - accuracy: 0.7531\n","Epoch 167/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5101 - accuracy: 0.7532\n","Epoch 168/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5101 - accuracy: 0.7534\n","Epoch 169/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5098 - accuracy: 0.7540\n","Epoch 170/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5103 - accuracy: 0.7536\n","Epoch 171/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5103 - accuracy: 0.7538\n","Epoch 172/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5104 - accuracy: 0.7540\n","Epoch 173/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5104 - accuracy: 0.7543\n","Epoch 174/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5097 - accuracy: 0.7545\n","Epoch 175/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5104 - accuracy: 0.7538\n","Epoch 176/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5104 - accuracy: 0.7537\n","Epoch 177/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5098 - accuracy: 0.7544\n","Epoch 178/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5100 - accuracy: 0.7538\n","Epoch 179/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5094 - accuracy: 0.7539\n","Epoch 180/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5101 - accuracy: 0.7539\n","Epoch 181/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5103 - accuracy: 0.7543\n","Epoch 182/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5099 - accuracy: 0.7527\n","Epoch 183/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5095 - accuracy: 0.7543\n","Epoch 184/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5101 - accuracy: 0.7536\n","Epoch 185/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5100 - accuracy: 0.7538\n","Epoch 186/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5097 - accuracy: 0.7534\n","Epoch 187/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5096 - accuracy: 0.7531\n","Epoch 188/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5105 - accuracy: 0.7532\n","Epoch 189/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5097 - accuracy: 0.7526\n","Epoch 190/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5097 - accuracy: 0.7533\n","Epoch 191/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5099 - accuracy: 0.7534\n","Epoch 192/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5097 - accuracy: 0.7541\n","Epoch 193/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5099 - accuracy: 0.7534\n","Epoch 194/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5096 - accuracy: 0.7548\n","Epoch 195/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5101 - accuracy: 0.7539\n","Epoch 196/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5096 - accuracy: 0.7536\n","Epoch 197/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5099 - accuracy: 0.7535\n","Epoch 198/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5097 - accuracy: 0.7538\n","Epoch 199/200\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5097 - accuracy: 0.7533\n","Epoch 200/200\n","698/698 [==============================] - 4s 5ms/step - loss: 0.5092 - accuracy: 0.7540\n"]}]},{"cell_type":"code","source":["# re-run the hp setup \n","\n","# def create_model(hp):\n","#     nn_model_opt = tf.keras.models.Sequential()\n","\n","#     # Allow kerastuner to decide which activation function to use in hidden layers\n","#     activation = hp.Choice('activation',['relu','tanh'])\n","    \n","#     # Allow kerastuner to decide number of neurons in first layer\n","#     nn_model_opt.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n","#         min_value=1,\n","#         max_value=50,\n","#         step=2), activation=activation, input_dim=55))\n","\n","#     # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n","#     for i in range(hp.Int('num_layers', 1, 50)):\n","#         nn_model_opt.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n","#             min_value=1,\n","#             max_value=50,\n","#             step=2),\n","#             activation=activation))\n","    \n","#     nn_model_opt.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n","\n","#     # Compile the model\n","#     nn_model_opt.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n","    \n","#     return nn_model_opt"],"metadata":{"id":"unjweezU_8tO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import the kerastuner library\n","# !pip install -q -U keras-tuner\n","# import keras_tuner as kt\n","\n","# tuner = kt.Hyperband(\n","#     create_model,\n","#     objective=\"val_accuracy\",\n","#     max_epochs=20,\n","#     overwrite = True,\n","#     hyperband_iterations=2)"],"metadata":{"id":"a5quvNE2G5aw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# re-run tuner search to look for the best hps (I prematurely stopped the run because one of the trials already passed the 75th percent benchmark)\n","tuner.search(X_train_scaled,y_train,epochs=20,validation_data=(X_test_scaled,y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Rqwb-ysCHCMI","executionInfo":{"status":"error","timestamp":1645516733640,"user_tz":480,"elapsed":1272763,"user":{"displayName":"Emily Ye","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15978148076169761414"}},"outputId":"d3db2696-ce55-45bb-e1f7-2e9d3303a05d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Trial 31 Complete [00h 00m 22s]\n","val_accuracy: 0.5223058462142944\n","\n","Best val_accuracy So Far: 0.7542327046394348\n","Total elapsed time: 00h 20m 59s\n","\n","Search: Running Trial #32\n","\n","Hyperparameter    |Value             |Best Value So Far \n","activation        |relu              |tanh              \n","first_units       |31                |33                \n","num_layers        |27                |18                \n","units_0           |7                 |43                \n","units_1           |13                |15                \n","units_2           |9                 |9                 \n","units_3           |43                |15                \n","units_4           |49                |33                \n","units_5           |49                |45                \n","units_6           |37                |5                 \n","units_7           |49                |11                \n","units_8           |23                |17                \n","units_9           |39                |17                \n","units_10          |43                |23                \n","units_11          |19                |5                 \n","units_12          |29                |41                \n","units_13          |47                |49                \n","units_14          |15                |41                \n","units_15          |15                |45                \n","units_16          |35                |47                \n","units_17          |43                |43                \n","units_18          |41                |17                \n","units_19          |23                |29                \n","units_20          |41                |21                \n","units_21          |35                |5                 \n","units_22          |31                |15                \n","units_23          |27                |37                \n","units_24          |39                |25                \n","units_25          |9                 |17                \n","units_26          |21                |27                \n","units_27          |49                |17                \n","units_28          |33                |39                \n","units_29          |17                |45                \n","units_30          |5                 |33                \n","units_31          |15                |49                \n","units_32          |27                |35                \n","units_33          |27                |39                \n","units_34          |5                 |43                \n","units_35          |43                |45                \n","units_36          |27                |21                \n","units_37          |29                |31                \n","units_38          |37                |27                \n","units_39          |43                |13                \n","units_40          |21                |35                \n","units_41          |23                |27                \n","units_42          |41                |49                \n","units_43          |7                 |5                 \n","units_44          |21                |25                \n","units_45          |41                |47                \n","units_46          |19                |9                 \n","units_47          |27                |37                \n","units_48          |15                |1                 \n","tuner/epochs      |3                 |20                \n","tuner/initial_e...|0                 |0                 \n","tuner/bracket     |2                 |0                 \n","tuner/round       |0                 |0                 \n","\n","Epoch 1/3\n","698/698 [==============================] - 7s 7ms/step - loss: 0.6150 - accuracy: 0.6737 - val_loss: 0.5751 - val_accuracy: 0.7466\n","Epoch 2/3\n","698/698 [==============================] - 4s 6ms/step - loss: 0.5756 - accuracy: 0.7347 - val_loss: 0.5708 - val_accuracy: 0.7209\n","Epoch 3/3\n","240/698 [=========>....................] - ETA: 2s - loss: 0.5601 - accuracy: 0.7262"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-80-3571a43fa60a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# re-run tuner search to look for the best hps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# objective left unspecified,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_tuner/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \"\"\"\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["# this experimentation will be finalized in the adjacent notebook"],"metadata":{"id":"mcwxqDlPHI3I"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Starter_Code.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}
